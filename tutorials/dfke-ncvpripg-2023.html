<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Data-free Knowledge Extraction from Deep Neural Networks</title>
  
  <meta name="author" content="Data-free Knowledge Extraction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">  
</head>

<body>


  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>          
          
          <tr style="padding:0px">
            <td style="padding:2.5%;width:100%;vertical-align:middle">
             
              <h1 style="font-size:2vw;"Data-free Knowledge Extraction from Deep Neural Networks</h1>
              <p style="text-align:center"> <strong>Data-free Knowledge Extraction from Deep Neural Networks</strong></p> 
            </td>
            
          </tr>
        </tbody></table>

        <p style="text-align:center">Welcome to the tutorial on Data-free Knowledge Extraction to be held as part of the <a href="https://events.iitj.ac.in/ncvpripg2023/">NCVPRIPG 2023</a> conference.</p>
        
        <!--             Abstract section              -->          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Abstract</strong></heading>
              <p>
                Data-free Knowledge Extraction (DFKE) refers to the process of extracting useful information from a trained deep neural network (DNN) without accessing the underlying training data over which the DNN is trained. 
                The extracted information can be diverse. For instance, it can be a replica of the DNN itself, some sensitive information about the underlying training data, or patterns from thereof, etc. DFKE can be extremely 
                vexing particularly in deployments like MLaaS (Machine Learning as a service). Considering the amount of data, human expertise, and computational resources that are typically required to learn the sophisticated DNNs, 
                it is natural to consider them as intellectual property. Therefore, they need to be protected against any such attempts of extraction (referred to as attacks). On the other hand, philosophically it would be interesting 
                to (i) understand the utility of these trained models without their training data, and (ii) formulate guarantees on the information leakage (or extraction). In this tutorial, I plan to first introduce the phenomenon 
                of data-free model extraction and discuss different ways in which it can be manifested, both in white-box and black-box scenarios. In the later part, I will focus more on the potential threats of leaking sensitive 
                information about the training data to a dishonest user in the form of different attacks. Finally, I will discuss some of the active directions to investigate further.
                    
              </p>
            </td>
          </tr>
        </tbody></table>
<!--             Topics section              -->          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Topics to be discussed</strong></heading>
              <ul>
                    <li> Introduction
                          <ul>
                          <li>Knowledge Distillation</li>
                          <li>Noise Optimization towards CNN visualization</li>
                          <li>Generative Adversarial Networks (GAN)</li>
                          </ul>  
                    <li> Data-free Knowledge Distillation (towards creating a replica of the target model)
                          <ul>
                          <li>Via Noise Optimization</li>
                          <li>Via Generative Reconstruction</li>
                          </ul>
                    <li> Data-free attacks (towards extracting sensitive information about the training data)
                    <li> Conclusion and Future directions

              </ul>
             
            </td>
          </tr>
        </tbody></table>
<!--             Schedule section              -->        

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Schedule</strong></heading>
              <ul>
                    <li> Session 1: 2 - 4 PM, July 21, 2023 (Friday)
                    <li> Session 2: 4.30 - 5.30 PM, July 21, 2023 (Friday)  

              </ul>
             
            </td>
          </tr>
        </tbody></table>
  

  
<!--             Speakers section              -->        

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Speakers</strong></heading>
              <ul>
                    <li> <a href='https://krmopuri.github.io/'>Konda Reddy Mopuri</a>, IIT Hyderabad

              </ul>
             
            </td>
          </tr>
        </tbody></table>

<!--             References section              -->        

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Bibliography and References</strong></heading>
              <ul>
               <li> Knowledge Distillation
                 <ol>
                  <li>Konwledge Distillation, Hinton et. al.[<a href='https://arxiv.org/abs/1503.02531'>NIPS 2014 Workshop</a>]</li>
                  <li>Survey on Knowledge Distillation,  [<a href='https://arxiv.org/abs/2006.05525'>IJCV 2021</a>]. </li>
                 </ol>
               <li> Noise Optimization
                 <ol>
                 <li>Class Impressions, Mopuri et al. [<a href='https://openaccess.thecvf.com/content_ECCV_2018/papers/Konda_Reddy_Mopuri_Ask_Acquire_and_ECCV_2018_paper.pdf'>ECCV 2018</a>]</li>
                 <li>Data Impressions, Mopuri et al. [<a href='http://proceedings.mlr.press/v97/nayak19a/nayak19a.pdf'>ICML 2019</a>]</li>
                 <li>Mining Data Impressions as a Substitute for training data [<a href='https://ieeexplore.ieee.org/iel7/34/4359286/09540299.pdf'>TPAMI 2021</a>]</li>
                 <li>Data-free Knowledge Distillation in Deep Neural Networks, Lopes et al. [<a href='https://arxiv.org/abs/1710.07535'>NeurIPS 2017 Workshop</a>]</li>
                 <li>[<a href='https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html'>Deep Dream</a>] by Google, 2015</li>
                 <li>Deep Inversion, [<a href='https://arxiv.org/pdf/1912.08795.pdf'>CVPR 2020</a>]</li>                 
                 </ol>
               <li> Generative Reconstruction
                 <ol>
                   <li>GANs by Ian Goodfellow et al. [<a href='https://arxiv.org/abs/1406.2661'>NeurIPS 2014</a>]</li>
                   <li>DAFL [<a href='https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Data-Free_Learning_of_Student_Networks_ICCV_2019_paper.pdf'>ICCV 2019</a>]</li>
                   <li>DFKA [<a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Ye_Data-Free_Knowledge_Amalgamation_via_Group-Stack_Dual-GAN_CVPR_2020_paper.pdf'>CVPR 2021</a>]</li>
                   <li>Batch Normalization Statistics: [<a href='https://arxiv.org/abs/2012.05578'>Luo et al. 2020</a>][<a href='https://arxiv.org/abs/1912.01274'>Haroush et al. 2020</a>][<a href='https://arxiv.org/abs/1911.02888'>Besnier et al. 2019</a>]</li>                   
                 </ol>
               <li> Arbitrary Transfer set (and/or Weakly related set)
                 <ol>
                   <li>Data-enriching GANs, Addepalli et al. [<a href='https://arxiv.org/abs/1912.11960'>AAAI 2020</a>]</li>
                   <li>Focus on diversity: [<a href='https://www.ijcai.org/proceedings/2021/0327.pdf'>Fang et al. 2021</a>][<a href='https://ieeexplore.ieee.org/document/9414674'>Han et al. 2021</a>]</li>
                   <li>Noise and Arbitrary Data as the Transfer Set, Mopuri and Nayak et al. [<a href='https://arxiv.org/abs/2011.09113'>WACV 2021</a>]</li>
                   <li>Learning Students in the Wild, Chen et al. [<a href='https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_Student_Networks_in_the_Wild_CVPR_2021_paper.pdf'>CVPR 2021</a>]</li>
                 </ol>
               <li> Adversarial Exploration
                 <ol>
                   <li>ZSKT, Micaelli et al. [<a href='https://openreview.net/pdf?id=B1x00VHgIH'>NeurIPS 2019</a>]</li>
                   <li>DFAD, Fang et al. [<a href='https://arxiv.org/abs/1912.11006'>2020</a>]</li>
                 </ol>
                <li> Other Applications of DFKE 
                 <ol>
                   <li>Object Detection and Semantic Segmentation: [<a href='https://arxiv.org/abs/1912.11006'>DFAD, 2020</a>] [<a href='https://www.bmvc2021-virtualconference.com/assets/papers/0906.pdf'>Object Detection</a> BMVC 2021]</li>
                   <li>Domain Adaptation and Continual Learning: [<a href='https://ieeexplore.ieee.org/iel7/34/4359286/09540299.pdf'>TPAMI 2021</a>]</li>
                 </ol>
                <li> Black-box setting and other attacks
                 <ol>
                   <li>Stealing ML models via prediction APIs [<a href='https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf'>USENIX</a>a 2016]<mark>(attacks on online services of Amazon and BigML)</mark></li>
                   <li>Membership Inference attack, [<a href='https://www.cs.cornell.edu/~shmat/shmat_oak17.pdf'>Shokri et al. 2017]</a></li>
                   <li>Model Inversion attack, [<a href='https://arxiv.org/pdf/1911.07135.pdf'>Zhang et al.</a>]</li>                   
                   <li>DFME (soft label) [<a href='https://arxiv.org/abs/2011.14779'>CVPR, 2021</a>]</li>
                   <li>DFME (hard label) [<a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.pdf'>CVPR 2022</a>]</li>
                   
                 </ol>
               </ul>
              
             
            </td>
          </tr>
        </tbody></table>
  
 <!--             Contact section              -->        

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><strong>Contact</strong></heading>
              <ul>
                    <a href="mailto:krmopuri@ai.iith.ac.in">Email</a>

              </ul>
             
            </td>
          </tr>
        </tbody></table>       
        
</body>

</html>
