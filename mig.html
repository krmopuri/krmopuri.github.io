<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Machine Intelligence Group, IIT Tirupati</title>
  
  <meta name="author" content="Machine Intelligence Group">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/MIG-logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <p style="text-align:center">
                <!-- <name>Machine Intelligence Group</name> -->
                <a href="images/MIG-logo-title.png"><img style="width:100%;max-width:85%" alt="profile photo" src="images/MIG-logo-title.png" class="hoverZoomLink"></a>
              </p>
              <p>We are an enthusiastic research lab at <a href="https://iittp.ac.in/">Indian Institute of Technology, Tirupati</a>, led by <a href="https://kmopuri.github.io/">Dr. Konda Reddy Mopuri</a>.
                The research interests of our group mainly include Machine Learning, Artifical Neural Networks (Deep Learning), Artificial Intelligence, Computer Vision, Image/Signal Processing, Data Science, Optimization, and other related areas.
              </p>
              
              <p style="text-align:center">
                <a href="publications.html">Publications</a> &nbsp/&nbsp
                <!-- <a href="recognition.html">Recognition</a> &nbsp/&nbsp -->
                <a href="openings.html">Openings</a> &nbsp/&nbsp
                <a href="mailto:mig.iittp@gmail.com">Email</a>
                <!-- <a href="https://twitter.com/mkreddy48">Twitter</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <!-- <a href="images/MIG-logo-title.png"><img style="width:100%;max-width:85%" alt="profile photo" src="images/MIG-logo-title.png" class="hoverZoomLink"></a> -->
            </td>
          </tr>
        <!--             News section              -->  
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                    <li>April 2021: Started the group website. </li>
              </ul>
            </td>
          </tr>
        <!--             People section              -->  
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>People</heading>
              <ul>
                    <li> Sudheer Kumar Daram - M. Tech (Thesis), Dept. of CSE, IIT Tirupati
                      <br></br> 
                    <li> Aditya Prakash Patra - Research Intern (B. Tech, IIT Patna)
                    <li> Hrushikesh Kyathari - Research Intern (UG student from IIT Guwahati)
                    <li> Venkat Sai Gopal - Research Intern (UG student from IIIT Benguluru)
              </ul>
            </td>
          </tr>
        <!--             Research section              -->
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Following is an approximate clustering and labeling of the research (click on the label to find relevant research; Note that earlier works of Dr. Mopuri from his previous affiliations are not removed from the list).
              </p>
            </td>
          </tr>
        </tbody></table>
                      
<!-- Research 5: Long-Tailed Training Data -->                      
                      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/longtail.png' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="long-tail.html">
                <papertitle>Long-Tailed Training Data</papertitle>
              </a>
              <br>
              
              <p></p>
              <p>Real-world datasets exhibit skewed distributions, generally with a long-tail. In other words, only a few categories contribute majority of the samples, while
                most of the other classes claim relatively small number of samples. Classifiers trained on such data perform poorly on the minority categories. We aim to 
                contribute effective solutions to alleviate the adverse effects casued by class imbalance in the training data.</p>
            </td>
          </tr>     

        </tbody></table>
  
  <!-- Research 4: Data Engineering for Deep Learning -->                      
                      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/data-engineering.JPG' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data-engineering.html">
                <papertitle>Data Engineering for Deep Learning</papertitle>
              </a>
              <br>
              
              <p></p>
              <p>In the digital era with the help of fast growing semiconductor technology we have created heaps of digital content (Images, videos, text, audio, etc.).
                This surely serves the data hungry deep learning in order to read the complex patterns in the data which would be otherwise difficult. However, it comes
                with the costs such as data redundancy, maintanance and distribution overhead, huge computational and time requirements to perform learning activities on these
                digital piles. We aim to investigate engineering solutions to these data and learning related challenges</p>
            </td>
          </tr>     

        </tbody></table>
<!-- Research 1: Robust Deep Learning -->                           
                      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='robustness.jpg' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="robustness.html">
                <papertitle>Robustness</papertitle>
              </a>
              <br>
              
              <p></p>
              <p>Deep CNNs are vulnerable to adversarial samples. There have been multiple approaches formulated to generate the adversarial samples. More importantly,
                adversarial samples can be transferred (generalized) across multiple models. This property allows an attacker to launch an attack without knowing the target 
                modelâ€™s internals, which makes them a dangerous threat for deploying the models in practice. Therefore, the effect of adversarial perturbations warrants
                the need for in depth analysis of this subject.</p>
            </td>
          </tr>     

        </tbody></table>

<!-- Research 2: Adaptable Deep Learning -->                      
                      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='adaptability.jpg' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="adaptability.html">
                <papertitle>Adaptability</papertitle>
              </a>
              <br>
              
              <p></p>
              <p>Deep Learning has been data and resource intensive. However, real-world may challenge us with various constraints to apply these sophisticated tools.
                Adapting deep learning techniques/models (e.g. knowledge transfer, domain adaptation) across tasks and to challenging environments such as low data
                      and data-free scenarios is of high importance.</p>
            </td>
          </tr>     

        </tbody></table>
                      
<!-- Research 3: Interpretable Deep Learning -->                      
                      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='interpretability.JPG' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="interpretability.html">
                <papertitle>Interpretability</papertitle>
              </a>
              <br>
              
              <p></p>
              <p>Deep learning Models are complex machine learning systems with hundreds of layers and millions of parameters. Presence of advanced regularizers 
                 such as dropout and batch-normalization make the models less transparent. Because of end-to-end nature of the learning, models suffer from lesser
                 decomposability and hence most of us treat them as black-boxes. In order to make these models more transparent, we devise methods that provide 
                 visual explanations to the labels predicted by the recognition CNNs.</p>
            </td>
          </tr>     

        </tbody></table>

                      

<!--Link to the source of the website-->
                   
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source taken from <a href="https://jonbarron.info/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
